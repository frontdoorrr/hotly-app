"""
ìºì‹œ ì„±ëŠ¥ í†µí•© í…ŒìŠ¤íŠ¸

ì „ì²´ ìºì‹œ ì‹œìŠ¤í…œê³¼ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì˜ í†µí•© í…ŒìŠ¤íŠ¸ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
TDD ë°©ì‹ìœ¼ë¡œ ì‹¤ì œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤.
"""
import time
from datetime import datetime
from typing import Any, Dict, Optional, Tuple


class TestCachePerformanceIntegration:
    """ìºì‹œ ì„±ëŠ¥ í†µí•© í…ŒìŠ¤íŠ¸"""

    def test_end_to_end_cache_performance_flow(self):
        """ì¢…ë‹¨ê°„ ìºì‹œ ì„±ëŠ¥ í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
        # Given: í†µí•© ì‹œìŠ¤í…œ ì„¤ì •
        cache_system = {
            "l1_memory": {},  # ë©”ëª¨ë¦¬ ìºì‹œ
            "l2_disk": {},  # ë””ìŠ¤í¬ ìºì‹œ
            "l3_redis": {},  # Redis ìºì‹œ
            "stats": {
                "hit_count": 0,
                "miss_count": 0,
                "total_requests": 0,
                "response_times": [],
            },
        }

        performance_monitor = {
            "api_metrics": [],
            "cache_metrics": [],
            "query_metrics": [],
        }

        def get_from_cache(key: str) -> Tuple[Optional[Any], str, float]:
            """ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ"""
            start_time = time.perf_counter()
            cache_system["stats"]["total_requests"] += 1

            # L1 ë©”ëª¨ë¦¬ ìºì‹œ í™•ì¸
            if key in cache_system["l1_memory"]:
                data = cache_system["l1_memory"][key]
                cache_system["stats"]["hit_count"] += 1
                duration = (time.perf_counter() - start_time) * 1000
                cache_system["stats"]["response_times"].append(duration)
                return data, "L1", duration

            # L2 ë””ìŠ¤í¬ ìºì‹œ í™•ì¸
            if key in cache_system["l2_disk"]:
                data = cache_system["l2_disk"][key]
                # L1ì— ë³µì‚¬
                cache_system["l1_memory"][key] = data
                cache_system["stats"]["hit_count"] += 1
                duration = (time.perf_counter() - start_time) * 1000
                cache_system["stats"]["response_times"].append(duration)
                return data, "L2", duration

            # L3 Redis ìºì‹œ í™•ì¸
            if key in cache_system["l3_redis"]:
                data = cache_system["l3_redis"][key]
                # L1, L2ì— ë³µì‚¬
                cache_system["l1_memory"][key] = data
                cache_system["l2_disk"][key] = data
                cache_system["stats"]["hit_count"] += 1
                duration = (time.perf_counter() - start_time) * 1000
                cache_system["stats"]["response_times"].append(duration)
                return data, "L3", duration

            # ìºì‹œ ë¯¸ìŠ¤ - ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒ
            cache_system["stats"]["miss_count"] += 1
            duration = (time.perf_counter() - start_time) * 1000
            cache_system["stats"]["response_times"].append(duration)
            return None, "MISS", duration

        def set_to_cache(key: str, value: Any, ttl: int = 3600):
            """ìºì‹œì— ë°ì´í„° ì €ì¥"""
            cache_system["l1_memory"][key] = value
            cache_system["l2_disk"][key] = value
            cache_system["l3_redis"][key] = value

        def track_api_performance(endpoint: str, response_time: float, cache_hit: bool):
            """API ì„±ëŠ¥ ì¶”ì """
            performance_monitor["api_metrics"].append(
                {
                    "endpoint": endpoint,
                    "response_time": response_time,
                    "cache_hit": cache_hit,
                    "timestamp": datetime.now().isoformat(),
                }
            )

        # When: ì‹¤ì œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ ì‹œë®¬ë ˆì´ì…˜

        # ì‹œë‚˜ë¦¬ì˜¤ 1: ì²« ë²ˆì§¸ ìš”ì²­ (ìºì‹œ ë¯¸ìŠ¤)
        data, cache_level, duration = get_from_cache("places:seoul:restaurants")
        assert data is None
        assert cache_level == "MISS"
        assert duration > 0

        # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê°€ì ¸ì˜¨ í›„ ìºì‹œì— ì €ì¥
        places_data = {"places": [{"id": 1, "name": "ë§›ì§‘1"}, {"id": 2, "name": "ë§›ì§‘2"}]}
        set_to_cache("places:seoul:restaurants", places_data)
        track_api_performance("/api/v1/places", duration, False)

        # ì‹œë‚˜ë¦¬ì˜¤ 2: ë‘ ë²ˆì§¸ ìš”ì²­ (L1 ìºì‹œ íˆíŠ¸)
        data, cache_level, duration = get_from_cache("places:seoul:restaurants")
        assert data == places_data
        assert cache_level == "L1"
        assert duration < 5.0  # L1 ìºì‹œëŠ” ë§¤ìš° ë¹¨ë¼ì•¼ í•¨
        track_api_performance("/api/v1/places", duration, True)

        # ì‹œë‚˜ë¦¬ì˜¤ 3: ë‹¤ë¥¸ í‚¤ë¡œ ìš”ì²­ (ìºì‹œ ë¯¸ìŠ¤)
        data, cache_level, duration = get_from_cache("places:busan:cafes")
        assert data is None
        assert cache_level == "MISS"

        # ì‹œë‚˜ë¦¬ì˜¤ 4: L1 ìºì‹œ ì œê±° í›„ L2ì—ì„œ ì¡°íšŒ
        cache_system["l1_memory"].clear()  # L1 ìºì‹œ ë¹„ìš°ê¸°
        data, cache_level, duration = get_from_cache("places:seoul:restaurants")
        assert data == places_data
        assert cache_level == "L2"
        assert duration < 50.0  # L2 ìºì‹œëŠ” ì ë‹¹íˆ ë¹¨ë¼ì•¼ í•¨

        # Then: ì„±ëŠ¥ ì§€í‘œ ê²€ì¦
        stats = cache_system["stats"]
        assert stats["total_requests"] == 4
        assert stats["hit_count"] == 2
        assert stats["miss_count"] == 2

        hit_rate = stats["hit_count"] / stats["total_requests"]
        assert hit_rate == 0.5  # 50% ì ì¤‘ë¥ 

        avg_response_time = sum(stats["response_times"]) / len(stats["response_times"])
        assert avg_response_time < 100.0  # í‰ê·  100ms ì´í•˜

        # API ì„±ëŠ¥ ì§€í‘œ ê²€ì¦
        api_metrics = performance_monitor["api_metrics"]
        assert len(api_metrics) == 2

        cache_hit_requests = [m for m in api_metrics if m["cache_hit"]]
        cache_miss_requests = [m for m in api_metrics if not m["cache_hit"]]

        assert len(cache_hit_requests) == 1
        assert len(cache_miss_requests) == 1
        assert (
            cache_hit_requests[0]["response_time"]
            < cache_miss_requests[0]["response_time"]
        )

        print("âœ… ì¢…ë‹¨ê°„ ìºì‹œ ì„±ëŠ¥ í”Œë¡œìš° í…ŒìŠ¤íŠ¸ í†µê³¼")

    def test_cache_performance_under_load(self):
        """ë¶€í•˜ ìƒí™©ì—ì„œ ìºì‹œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        # Given: ë¶€í•˜ í…ŒìŠ¤íŠ¸ í™˜ê²½
        cache_system = {
            "data": {},
            "stats": {
                "requests": 0,
                "hits": 0,
                "total_time": 0,
                "concurrent_requests": 0,
                "max_concurrent": 0,
            },
        }

        def simulate_cache_request(key: str, is_hit: bool = True) -> float:
            """ìºì‹œ ìš”ì²­ ì‹œë®¬ë ˆì´ì…˜"""
            start_time = time.perf_counter()
            cache_system["stats"]["requests"] += 1
            cache_system["stats"]["concurrent_requests"] += 1

            # ìµœëŒ€ ë™ì‹œ ìš”ì²­ ìˆ˜ ì¶”ì 
            if (
                cache_system["stats"]["concurrent_requests"]
                > cache_system["stats"]["max_concurrent"]
            ):
                cache_system["stats"]["max_concurrent"] = cache_system["stats"][
                    "concurrent_requests"
                ]

            # ìºì‹œ íˆíŠ¸/ë¯¸ìŠ¤ì— ë”°ë¥¸ ì§€ì—° ì‹œë®¬ë ˆì´ì…˜
            if is_hit:
                time.sleep(0.001)  # 1ms (ìºì‹œ íˆíŠ¸)
                cache_system["stats"]["hits"] += 1
            else:
                time.sleep(0.050)  # 50ms (ìºì‹œ ë¯¸ìŠ¤, DB ì¡°íšŒ)

            cache_system["stats"]["concurrent_requests"] -= 1
            duration = (time.perf_counter() - start_time) * 1000
            cache_system["stats"]["total_time"] += duration

            return duration

        # When: ë‹¤ì–‘í•œ ë¶€í•˜ íŒ¨í„´ í…ŒìŠ¤íŠ¸

        # íŒ¨í„´ 1: ìˆœì°¨ì  ìš”ì²­ (80% ìºì‹œ íˆíŠ¸)
        sequential_times = []
        for i in range(100):
            is_hit = i % 5 != 0  # 80% íˆíŠ¸ìœ¨
            duration = simulate_cache_request(f"key_{i}", is_hit)
            sequential_times.append(duration)

        # íŒ¨í„´ 2: ë™ì¼ í‚¤ ë°˜ë³µ ìš”ì²­ (ê±°ì˜ 100% ìºì‹œ íˆíŠ¸)
        popular_key_times = []
        for i in range(50):
            is_hit = i > 0  # ì²« ë²ˆì§¸ë§Œ ë¯¸ìŠ¤
            duration = simulate_cache_request("popular_key", is_hit)
            popular_key_times.append(duration)

        # Then: ë¶€í•˜ ì„±ëŠ¥ ì§€í‘œ ê²€ì¦
        stats = cache_system["stats"]
        total_requests = stats["requests"]
        hit_rate = stats["hits"] / total_requests
        avg_response_time = stats["total_time"] / total_requests

        assert total_requests == 150
        assert hit_rate > 0.85  # 85% ì´ìƒ ì ì¤‘ë¥ 
        assert avg_response_time < 20.0  # í‰ê·  20ms ì´í•˜
        assert stats["max_concurrent"] >= 1  # ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ í™•ì¸

        # ìˆœì°¨ ìš”ì²­ vs ì¸ê¸° í‚¤ ìš”ì²­ ì„±ëŠ¥ ë¹„êµ
        avg_sequential = sum(sequential_times) / len(sequential_times)
        avg_popular = sum(popular_key_times) / len(popular_key_times)

        assert avg_popular < avg_sequential  # ì¸ê¸° í‚¤ê°€ ë” ë¹¨ë¼ì•¼ í•¨

        print("âœ… ë¶€í•˜ ìƒí™©ì—ì„œ ìºì‹œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í†µê³¼")

    def test_cache_eviction_and_performance_impact(self):
        """ìºì‹œ ì œê±° ë° ì„±ëŠ¥ ì˜í–¥ í…ŒìŠ¤íŠ¸"""
        # Given: ì œí•œëœ í¬ê¸°ì˜ ìºì‹œ ì‹œìŠ¤í…œ
        MAX_CACHE_SIZE = 10

        cache_system = {
            "l1_cache": {},  # LRU ë©”ëª¨ë¦¬ ìºì‹œ
            "access_order": [],  # LRU ìˆœì„œ ì¶”ì 
            "stats": {
                "evictions": 0,
                "cache_size_history": [],
                "performance_degradation": [],
            },
        }

        def lru_cache_get(key: str) -> Tuple[Optional[Any], float]:
            """LRU ìºì‹œ ì¡°íšŒ"""
            start_time = time.perf_counter()

            if key in cache_system["l1_cache"]:
                # íˆíŠ¸: ì•¡ì„¸ìŠ¤ ìˆœì„œ ì—…ë°ì´íŠ¸
                cache_system["access_order"].remove(key)
                cache_system["access_order"].append(key)

                # ìºì‹œ íˆíŠ¸ëŠ” ë¹ ë¦„ (ë©”ëª¨ë¦¬ ì•¡ì„¸ìŠ¤)
                time.sleep(0.0001)  # 0.1ms ì‹œë®¬ë ˆì´ì…˜
                data = cache_system["l1_cache"][key]
                duration = (time.perf_counter() - start_time) * 1000
                return data, duration
            else:
                # ë¯¸ìŠ¤: ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ì‹œë®¬ë ˆì´ì…˜
                time.sleep(0.01)  # 10ms ì‹œë®¬ë ˆì´ì…˜ (DB ì¡°íšŒ)
                duration = (time.perf_counter() - start_time) * 1000
                return None, duration

        def lru_cache_set(key: str, value: Any):
            """LRU ìºì‹œ ì €ì¥"""
            if key in cache_system["l1_cache"]:
                # ê¸°ì¡´ í‚¤ ì—…ë°ì´íŠ¸
                cache_system["access_order"].remove(key)
                cache_system["access_order"].append(key)
                cache_system["l1_cache"][key] = value
            else:
                # ìƒˆ í‚¤ ì¶”ê°€
                if len(cache_system["l1_cache"]) >= MAX_CACHE_SIZE:
                    # LRU ì œê±°
                    lru_key = cache_system["access_order"].pop(0)
                    del cache_system["l1_cache"][lru_key]
                    cache_system["stats"]["evictions"] += 1

                cache_system["l1_cache"][key] = value
                cache_system["access_order"].append(key)

            # ìºì‹œ í¬ê¸° íˆìŠ¤í† ë¦¬ ê¸°ë¡
            cache_system["stats"]["cache_size_history"].append(
                len(cache_system["l1_cache"])
            )

        # When: ìºì‹œ ì œê±°ê°€ ë°œìƒí•˜ëŠ” ì‹œë‚˜ë¦¬ì˜¤

        # ì‹œë‚˜ë¦¬ì˜¤ 1: ìºì‹œ ìš©ëŸ‰ ì´ˆê³¼ë¡œ ì¸í•œ ì œê±°
        for i in range(15):  # MAX_CACHE_SIZEë¥¼ ì´ˆê³¼
            lru_cache_set(f"key_{i}", f"data_{i}")

        assert len(cache_system["l1_cache"]) == MAX_CACHE_SIZE
        assert cache_system["stats"]["evictions"] == 5  # 5ê°œê°€ ì œê±°ë˜ì–´ì•¼ í•¨

        # ì‹œë‚˜ë¦¬ì˜¤ 2: ì œê±°ëœ í‚¤ ì¬ìš”ì²­ìœ¼ë¡œ ì¸í•œ ì„±ëŠ¥ ì €í•˜
        performance_before_eviction = []
        performance_after_eviction = []

        # í˜„ì¬ ìºì‹œì— ìˆëŠ” í‚¤ë“¤ì˜ ì„±ëŠ¥ (íˆíŠ¸)
        for key in list(cache_system["l1_cache"].keys())[:5]:
            _, duration = lru_cache_get(key)
            performance_before_eviction.append(duration)

        # ì œê±°ëœ í‚¤ë“¤ì˜ ì„±ëŠ¥ (ë¯¸ìŠ¤)
        for i in range(5):
            _, duration = lru_cache_get(f"key_{i}")  # ì œê±°ëœ í‚¤ë“¤
            performance_after_eviction.append(duration)

        # Then: ì œê±° ì˜í–¥ ë¶„ì„
        avg_hit_time = sum(performance_before_eviction) / len(
            performance_before_eviction
        )
        avg_miss_time = sum(performance_after_eviction) / len(
            performance_after_eviction
        )

        assert avg_miss_time > avg_hit_time  # ë¯¸ìŠ¤ê°€ íˆíŠ¸ë³´ë‹¤ ëŠë ¤ì•¼ í•¨

        performance_degradation = (avg_miss_time - avg_hit_time) / avg_hit_time
        cache_system["stats"]["performance_degradation"].append(performance_degradation)

        assert performance_degradation > 0  # ì„±ëŠ¥ ì €í•˜ ë°œìƒ

        # ìºì‹œ í¬ê¸°ê°€ ì ì ˆíˆ ê´€ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
        max_cache_size = max(cache_system["stats"]["cache_size_history"])
        assert max_cache_size == MAX_CACHE_SIZE

        print("âœ… ìºì‹œ ì œê±° ë° ì„±ëŠ¥ ì˜í–¥ í…ŒìŠ¤íŠ¸ í†µê³¼")


class TestPerformanceDashboardIntegration:
    """ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ í†µí•© í…ŒìŠ¤íŠ¸"""

    def test_real_time_performance_monitoring(self):
        """ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í†µí•© í…ŒìŠ¤íŠ¸"""
        # Given: ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
        monitoring_system = {
            "current_metrics": {},
            "metrics_history": [],
            "alerts": [],
            "performance_trends": {},
        }

        def collect_system_metrics() -> Dict[str, Any]:
            """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
            import random

            return {
                "timestamp": datetime.now().isoformat(),
                "cpu_usage": random.uniform(20, 90),
                "memory_usage": random.uniform(30, 85),
                "response_time_avg": random.uniform(50, 500),
                "response_time_p95": random.uniform(100, 1000),
                "cache_hit_rate": random.uniform(0.6, 0.95),
                "error_rate": random.uniform(0, 0.1),
                "requests_per_second": random.randint(50, 300),
                "active_connections": random.randint(10, 100),
            }

        def update_monitoring_dashboard(metrics: Dict[str, Any]):
            """ëŒ€ì‹œë³´ë“œ ì—…ë°ì´íŠ¸"""
            monitoring_system["current_metrics"] = metrics
            monitoring_system["metrics_history"].append(metrics)

            # ìµœê·¼ 100ê°œë§Œ ìœ ì§€
            if len(monitoring_system["metrics_history"]) > 100:
                monitoring_system["metrics_history"] = monitoring_system[
                    "metrics_history"
                ][-100:]

            # ì•Œë¦¼ ì²´í¬
            if metrics["response_time_p95"] > 800:
                monitoring_system["alerts"].append(
                    {
                        "type": "high_response_time",
                        "message": f"P95 response time: {metrics['response_time_p95']:.1f}ms",
                        "timestamp": metrics["timestamp"],
                        "severity": "warning",
                    }
                )

            if metrics["cache_hit_rate"] < 0.7:
                monitoring_system["alerts"].append(
                    {
                        "type": "low_cache_hit_rate",
                        "message": f"Cache hit rate: {metrics['cache_hit_rate']:.1%}",
                        "timestamp": metrics["timestamp"],
                        "severity": "warning",
                    }
                )

        def analyze_performance_trends():
            """ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„"""
            if len(monitoring_system["metrics_history"]) < 2:
                return {"trend": "insufficient_data"}

            recent_metrics = monitoring_system["metrics_history"][-10:]  # ìµœê·¼ 10ê°œ
            older_metrics = (
                monitoring_system["metrics_history"][-20:-10]
                if len(monitoring_system["metrics_history"]) >= 20
                else []
            )

            if not older_metrics:
                return {"trend": "insufficient_historical_data"}

            # í‰ê·  ë¹„êµ
            recent_avg_response_time = sum(
                m["response_time_avg"] for m in recent_metrics
            ) / len(recent_metrics)
            older_avg_response_time = sum(
                m["response_time_avg"] for m in older_metrics
            ) / len(older_metrics)

            recent_avg_cache_hit = sum(
                m["cache_hit_rate"] for m in recent_metrics
            ) / len(recent_metrics)
            older_avg_cache_hit = sum(m["cache_hit_rate"] for m in older_metrics) / len(
                older_metrics
            )

            trend_analysis = {
                "response_time_trend": "improving"
                if recent_avg_response_time < older_avg_response_time
                else "degrading",
                "cache_hit_trend": "improving"
                if recent_avg_cache_hit > older_avg_cache_hit
                else "degrading",
                "recent_avg_response_time": recent_avg_response_time,
                "older_avg_response_time": older_avg_response_time,
                "recent_avg_cache_hit": recent_avg_cache_hit,
                "older_avg_cache_hit": older_avg_cache_hit,
            }

            monitoring_system["performance_trends"] = trend_analysis
            return trend_analysis

        # When: ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œë‚˜ë¦¬ì˜¤

        # ì‹œë‚˜ë¦¬ì˜¤ 1: ì •ìƒ ìƒíƒœ ëª¨ë‹ˆí„°ë§
        for _ in range(10):
            metrics = collect_system_metrics()
            update_monitoring_dashboard(metrics)
            time.sleep(0.01)  # 10ms ê°„ê²©

        # ì‹œë‚˜ë¦¬ì˜¤ 2: ì„±ëŠ¥ ì €í•˜ ìƒí™©
        for _ in range(5):
            metrics = collect_system_metrics()
            # ì„±ëŠ¥ ì €í•˜ ì‹œë®¬ë ˆì´ì…˜
            metrics.update(
                {
                    "response_time_p95": 900,  # ë†’ì€ ì‘ë‹µ ì‹œê°„
                    "cache_hit_rate": 0.6,  # ë‚®ì€ ìºì‹œ ì ì¤‘ë¥ 
                    "cpu_usage": 85,  # ë†’ì€ CPU ì‚¬ìš©ë¥ 
                }
            )
            update_monitoring_dashboard(metrics)
            time.sleep(0.01)

        # ì‹œë‚˜ë¦¬ì˜¤ 3: ì„±ëŠ¥ íšŒë³µ
        for _ in range(5):
            metrics = collect_system_metrics()
            # ì„±ëŠ¥ íšŒë³µ ì‹œë®¬ë ˆì´ì…˜
            metrics.update(
                {
                    "response_time_p95": 200,  # ë‚®ì€ ì‘ë‹µ ì‹œê°„
                    "cache_hit_rate": 0.9,  # ë†’ì€ ìºì‹œ ì ì¤‘ë¥ 
                    "cpu_usage": 40,  # ë‚®ì€ CPU ì‚¬ìš©ë¥ 
                }
            )
            update_monitoring_dashboard(metrics)
            time.sleep(0.01)

        # Then: ëª¨ë‹ˆí„°ë§ ê²°ê³¼ ê²€ì¦
        assert len(monitoring_system["metrics_history"]) == 20
        assert "timestamp" in monitoring_system["current_metrics"]

        # ì•Œë¦¼ ìƒì„± í™•ì¸
        alerts = monitoring_system["alerts"]
        response_time_alerts = [a for a in alerts if a["type"] == "high_response_time"]
        cache_hit_alerts = [a for a in alerts if a["type"] == "low_cache_hit_rate"]

        assert len(response_time_alerts) > 0  # ì‘ë‹µ ì‹œê°„ ì•Œë¦¼ ë°œìƒ
        assert len(cache_hit_alerts) > 0  # ìºì‹œ ì ì¤‘ë¥  ì•Œë¦¼ ë°œìƒ

        # íŠ¸ë Œë“œ ë¶„ì„
        trends = analyze_performance_trends()
        assert "response_time_trend" in trends
        assert "cache_hit_trend" in trends
        assert trends["response_time_trend"] in ["improving", "degrading"]
        assert trends["cache_hit_trend"] in ["improving", "degrading"]

        print("âœ… ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼")


class TestAPIEndpointIntegration:
    """API ì—”ë“œí¬ì¸íŠ¸ í†µí•© í…ŒìŠ¤íŠ¸"""

    def test_performance_api_integration(self):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ API í†µí•© í…ŒìŠ¤íŠ¸"""
        # Given: API ì—”ë“œí¬ì¸íŠ¸ ì‹œë®¬ë ˆì´í„°

        def mock_api_call(
            endpoint: str, method: str = "GET", data: Dict = None
        ) -> Dict[str, Any]:
            """API í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜"""
            if endpoint == "/api/v1/performance/dashboard" and method == "GET":
                return {
                    "current_metrics": {
                        "response_time_avg": 150.5,
                        "cache_hit_rate": 0.85,
                        "error_rate": 0.02,
                        "timestamp": datetime.now().isoformat(),
                    },
                    "alerts": [
                        {
                            "type": "info",
                            "message": "System running normally",
                            "timestamp": datetime.now().isoformat(),
                        }
                    ],
                    "performance_ranking": [
                        {
                            "endpoint": "/health",
                            "avg_response_time": 5.2,
                            "success_rate": 1.0,
                        },
                        {
                            "endpoint": "/places",
                            "avg_response_time": 125.8,
                            "success_rate": 0.99,
                        },
                    ],
                }

            elif endpoint == "/api/v1/performance/metrics" and method == "POST":
                return {"message": "Metrics updated successfully"}

            elif endpoint == "/api/v1/performance/cache-stats" and method == "GET":
                return {
                    "overall": {"hit_rate": 0.85, "total_requests": 10000},
                    "l1_memory": {"hit_rate": 0.45, "size": "50MB"},
                    "l2_disk": {"hit_rate": 0.25, "size": "500MB"},
                    "l3_redis": {"hit_rate": 0.15, "size": "2GB"},
                }

            else:
                return {"error": "Endpoint not found"}

        # When: API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸

        # í…ŒìŠ¤íŠ¸ 1: ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì¡°íšŒ
        dashboard_response = mock_api_call("/api/v1/performance/dashboard")
        assert "current_metrics" in dashboard_response
        assert "alerts" in dashboard_response
        assert "performance_ranking" in dashboard_response
        assert dashboard_response["current_metrics"]["cache_hit_rate"] == 0.85

        # í…ŒìŠ¤íŠ¸ 2: ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        metrics_data = {
            "response_time": 200.0,
            "cache_hit_rate": 0.88,
            "error_rate": 0.01,
        }
        update_response = mock_api_call(
            "/api/v1/performance/metrics", "POST", metrics_data
        )
        assert update_response["message"] == "Metrics updated successfully"

        # í…ŒìŠ¤íŠ¸ 3: ìºì‹œ í†µê³„ ì¡°íšŒ
        cache_stats = mock_api_call("/api/v1/performance/cache-stats")
        assert "overall" in cache_stats
        assert "l1_memory" in cache_stats
        assert "l2_disk" in cache_stats
        assert "l3_redis" in cache_stats
        assert cache_stats["overall"]["hit_rate"] == 0.85

        # í…ŒìŠ¤íŠ¸ 4: ì˜ëª»ëœ ì—”ë“œí¬ì¸íŠ¸
        error_response = mock_api_call("/api/v1/invalid")
        assert "error" in error_response

        print("âœ… ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ API í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼")

    def test_cdn_api_integration(self):
        """CDN API í†µí•© í…ŒìŠ¤íŠ¸"""
        # Given: CDN API ì‹œë®¬ë ˆì´í„°
        cdn_storage = {}

        def mock_cdn_api(
            endpoint: str, method: str = "GET", data: Dict = None
        ) -> Dict[str, Any]:
            """CDN API í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜"""
            if endpoint == "/api/v1/cdn/upload" and method == "POST":
                if data:
                    file_id = f"file_{len(cdn_storage)}"
                    cdn_storage[file_id] = data
                    return {
                        "cdn_url": f"https://cdn.hotly.app/v1/{data['cdn_path']}",
                        "file_hash": "abc123def456",
                        "file_size": 1024,
                        "uploaded_at": datetime.now().isoformat(),
                    }
                return {"error": "No data provided"}

            elif endpoint == "/api/v1/cdn/optimize/image" and method == "POST":
                return {
                    "original_size": 51200,
                    "variants": {
                        "webp": {"size": 30720, "compression_ratio": 0.4},
                        "jpeg": {"size": 40960, "compression_ratio": 0.2},
                    },
                    "total_size_saved": 10240,
                }

            elif endpoint == "/api/v1/cdn/cache-headers" and method == "GET":
                return {
                    "headers": {
                        "Cache-Control": "public, max-age=31536000",
                        "ETag": '"abc123"',
                        "Expires": "Thu, 01 Jan 2025 00:00:00 GMT",
                    }
                }

            else:
                return {"error": "Endpoint not found"}

        # When: CDN API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸

        # í…ŒìŠ¤íŠ¸ 1: íŒŒì¼ ì—…ë¡œë“œ
        upload_data = {
            "local_path": "/local/images/logo.png",
            "cdn_path": "images/logo.png",
        }
        upload_response = mock_cdn_api("/api/v1/cdn/upload", "POST", upload_data)
        assert "cdn_url" in upload_response
        assert "file_hash" in upload_response
        assert upload_response["cdn_url"] == "https://cdn.hotly.app/v1/images/logo.png"

        # í…ŒìŠ¤íŠ¸ 2: ì´ë¯¸ì§€ ìµœì í™”
        optimization_response = mock_cdn_api(
            "/api/v1/cdn/optimize/image",
            "POST",
            {"image_path": "images/hero.png", "quality": 80},
        )
        assert "variants" in optimization_response
        assert "webp" in optimization_response["variants"]
        assert optimization_response["total_size_saved"] > 0

        # í…ŒìŠ¤íŠ¸ 3: ìºì‹œ í—¤ë” ìƒì„±
        headers_response = mock_cdn_api("/api/v1/cdn/cache-headers")
        assert "headers" in headers_response
        assert "Cache-Control" in headers_response["headers"]
        assert "ETag" in headers_response["headers"]

        print("âœ… CDN API í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼")


def main():
    """ìºì‹œ ì„±ëŠ¥ í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸ”„ ìºì‹œ ë° ì„±ëŠ¥ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 65)

    test_classes = [
        TestCachePerformanceIntegration(),
        TestPerformanceDashboardIntegration(),
        TestAPIEndpointIntegration(),
    ]

    total_passed = 0
    total_failed = 0

    for test_instance in test_classes:
        class_name = test_instance.__class__.__name__
        print(f"\nğŸ§ª {class_name} í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
        print("-" * 50)

        test_methods = [
            method for method in dir(test_instance) if method.startswith("test_")
        ]

        for method_name in test_methods:
            try:
                if hasattr(test_instance, "setup_method"):
                    test_instance.setup_method()

                test_method = getattr(test_instance, method_name)
                test_method()
                total_passed += 1
            except Exception as e:
                print(f"âŒ {method_name} ì‹¤íŒ¨: {e}")
                total_failed += 1

    print(f"\nğŸ“Š ìºì‹œ ì„±ëŠ¥ í†µí•© í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    print(f"   âœ… í†µê³¼: {total_passed}")
    print(f"   âŒ ì‹¤íŒ¨: {total_failed}")
    print(f"   ğŸ“ˆ ì „ì²´: {total_passed + total_failed}")

    if total_failed == 0:
        print("ğŸ† ëª¨ë“  ìºì‹œ ì„±ëŠ¥ í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼!")
        return True
    else:
        print(f"âš ï¸ {total_failed}ê°œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        return False


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
