# TRD: ì½”ìŠ¤ ê³µìœ  ë° í˜‘ì—… ê¸°ëŠ¥

## 1. ê¸°ìˆ  ê°œìš”
**ëª©ì :** PRD 05-sharing-system ìš”êµ¬ì‚¬í•­ì„ ì¶©ì¡±í•˜ê¸° ìœ„í•œ ì‹¤ì‹œê°„ í˜‘ì—… ê³µìœ  ì‹œìŠ¤í…œì˜ ê¸°ìˆ ì  êµ¬í˜„ ë°©ì•ˆ

**í•µì‹¬ ê¸°ìˆ  ìŠ¤íƒ:**
- ì‹¤ì‹œê°„ í†µì‹ : WebSocket + Socket.IO
- ë§í¬ ê´€ë¦¬: Short URL Service + Redis Cache
- í˜‘ì—… ì—”ì§„: Operational Transform (OT) + Conflict Resolution
- ê¶Œí•œ ê´€ë¦¬: RBAC (Role-Based Access Control)
- API: FastAPI + GraphQL (ì‹¤ì‹œê°„ êµ¬ë…)

---

## 2. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### 2-1. ì „ì²´ ì•„í‚¤í…ì²˜
```
[Mobile/Web Client]
    â†“ WebSocket/HTTP
[API Gateway + Load Balancer]
    â†“
[Sharing Service] â†” [Real-time Collaboration Engine]
    â†“                        â†“
[Permission Manager] â†” [WebSocket Manager]
    â†“                        â†“
[Share Link Service] â†” [Comment/Edit Sync Service]
    â†“                        â†“
[PostgreSQL] + [Redis] â†” [WebSocket Cluster]
```

### 2-2. ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ êµ¬ì„±
```
1. Share Management Service
   - ê³µìœ  ë§í¬ ìƒì„±/ê´€ë¦¬
   - ê¶Œí•œ ì²´í¬ ë° ì ‘ê·¼ ì œì–´
   - ë§Œë£Œ ê´€ë¦¬

2. Real-time Collaboration Service
   - WebSocket ì—°ê²° ê´€ë¦¬
   - ì‹¤ì‹œê°„ ë™ê¸°í™”
   - ì¶©ëŒ í•´ê²°

3. Comment System Service
   - ëŒ“ê¸€ CRUD
   - ë°˜ì‘(ì¢‹ì•„ìš”/ì‹«ì–´ìš”) ê´€ë¦¬
   - ìŠ¤íŒ¸ í•„í„°ë§

4. Notification Service
   - ê³µìœ /ëŒ“ê¸€ ì•Œë¦¼
   - ì´ë©”ì¼/í‘¸ì‹œ ì•Œë¦¼ ì „ì†¡
   - ì•Œë¦¼ ì„¤ì • ê´€ë¦¬
```

---

## 3. API ì„¤ê³„

### 3-1. ê³µìœ  ë§í¬ ê´€ë¦¬ API
```python
# ê³µìœ  ë§í¬ ìƒì„±
class ShareLinkCreateRequest(BaseModel):
    course_id: str
    permission_level: PermissionLevel
    expires_at: Optional[datetime] = None
    allow_comments: bool = True
    allow_edit: bool = False
    password: Optional[str] = None

class PermissionLevel(str, Enum):
    VIEW_ONLY = "view"
    COMMENT = "comment"
    EDIT = "edit"

class ShareLinkResponse(BaseModel):
    share_id: str
    share_url: str
    qr_code_url: str
    permission_level: PermissionLevel
    expires_at: Optional[datetime]
    created_at: datetime

# ê³µìœ  ë§í¬ ì ‘ê·¼
class ShareAccessRequest(BaseModel):
    share_id: str
    password: Optional[str] = None
    user_agent: Optional[str] = None
    referrer: Optional[str] = None

class ShareAccessResponse(BaseModel):
    course: SharedCourseDetail
    permission: UserPermission
    can_edit: bool
    can_comment: bool
    access_token: str  # WebSocket ì¸ì¦ìš©

class SharedCourseDetail(BaseModel):
    id: str
    name: str
    places: List[SharedPlaceDetail]
    created_by: UserInfo
    shared_at: datetime
    comments_count: int
    participants_count: int

class UserPermission(BaseModel):
    level: PermissionLevel
    can_view: bool
    can_comment: bool
    can_edit: bool
    can_share: bool
```

### 3-2. ì‹¤ì‹œê°„ í˜‘ì—… API (WebSocket)
```python
# WebSocket ë©”ì‹œì§€ ìŠ¤í‚¤ë§ˆ
class WSMessage(BaseModel):
    type: WSMessageType
    share_id: str
    user_id: Optional[str]
    data: Dict[str, Any]
    timestamp: datetime

class WSMessageType(str, Enum):
    # ì—°ê²° ê´€ë¦¬
    CONNECT = "connect"
    DISCONNECT = "disconnect"
    HEARTBEAT = "heartbeat"

    # ì½”ìŠ¤ í¸ì§‘
    COURSE_EDIT_START = "course_edit_start"
    COURSE_EDIT_END = "course_edit_end"
    COURSE_UPDATE = "course_update"

    # ëŒ“ê¸€ ì‹œìŠ¤í…œ
    COMMENT_ADD = "comment_add"
    COMMENT_UPDATE = "comment_update"
    COMMENT_DELETE = "comment_delete"
    COMMENT_REACTION = "comment_reaction"

    # ì‹œìŠ¤í…œ ì•Œë¦¼
    USER_JOIN = "user_join"
    USER_LEAVE = "user_leave"
    PERMISSION_CHANGE = "permission_change"

# ì½”ìŠ¤ í¸ì§‘ ë©”ì‹œì§€
class CourseEditMessage(BaseModel):
    operation: EditOperation
    place_id: Optional[str]
    position: Optional[int]
    data: Optional[Dict[str, Any]]

class EditOperation(str, Enum):
    ADD_PLACE = "add_place"
    REMOVE_PLACE = "remove_place"
    REORDER_PLACES = "reorder_places"
    UPDATE_PLACE = "update_place"
    UPDATE_COURSE_INFO = "update_course_info"

# ëŒ“ê¸€ ë©”ì‹œì§€
class CommentMessage(BaseModel):
    comment_id: Optional[str]
    place_id: Optional[str]  # ì „ì²´ ì½”ìŠ¤ ëŒ“ê¸€ì˜ ê²½ìš° None
    content: str
    parent_id: Optional[str]  # ëŒ€ëŒ“ê¸€ì˜ ê²½ìš°
    mentions: List[str] = []  # @ì‚¬ìš©ìëª…
```

### 3-3. ëŒ“ê¸€ ì‹œìŠ¤í…œ API
```python
class CommentCreateRequest(BaseModel):
    share_id: str
    place_id: Optional[str] = None  # Noneì´ë©´ ì „ì²´ ì½”ìŠ¤ ëŒ“ê¸€
    content: str = Field(..., min_length=1, max_length=500)
    parent_id: Optional[str] = None

class CommentResponse(BaseModel):
    id: str
    content: str
    author: UserInfo
    place_id: Optional[str]
    parent_id: Optional[str]
    replies_count: int
    reactions: Dict[str, int]  # {"ğŸ‘": 3, "â¤ï¸": 1}
    created_at: datetime
    updated_at: Optional[datetime]

class CommentReactionRequest(BaseModel):
    comment_id: str
    reaction: str = Field(..., regex=r'^[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF]+$')
    action: ReactionAction

class ReactionAction(str, Enum):
    ADD = "add"
    REMOVE = "remove"
```

---

## 4. ì‹¤ì‹œê°„ í˜‘ì—… ì—”ì§„

### 4-1. WebSocket ì—°ê²° ê´€ë¦¬
```python
class WebSocketManager:
    def __init__(self):
        self.connections: Dict[str, Set[WebSocketConnection]] = {}
        self.user_sessions: Dict[str, UserSession] = {}
        self.redis_client = Redis.from_url(settings.REDIS_URL)

    async def connect(self, websocket: WebSocket, share_id: str, access_token: str):
        # í† í° ê²€ì¦
        user_info = await self._verify_access_token(access_token)
        if not user_info:
            await websocket.close(code=1008, reason="Invalid access token")
            return

        # ê¶Œí•œ í™•ì¸
        permissions = await self._get_user_permissions(share_id, user_info.user_id)
        if not permissions.can_view:
            await websocket.close(code=1008, reason="Access denied")
            return

        # ì—°ê²° ë“±ë¡
        connection = WebSocketConnection(
            websocket=websocket,
            user_id=user_info.user_id,
            share_id=share_id,
            permissions=permissions,
            connected_at=datetime.utcnow()
        )

        if share_id not in self.connections:
            self.connections[share_id] = set()
        self.connections[share_id].add(connection)

        self.user_sessions[user_info.user_id] = UserSession(
            user_id=user_info.user_id,
            share_id=share_id,
            connection=connection
        )

        # ì ‘ì† ì•Œë¦¼
        await self._broadcast_to_share(share_id, WSMessage(
            type=WSMessageType.USER_JOIN,
            share_id=share_id,
            user_id=user_info.user_id,
            data={"user_info": user_info.dict()},
            timestamp=datetime.utcnow()
        ), exclude_user=user_info.user_id)

        # í˜„ì¬ ì ‘ì†ì ëª©ë¡ ì „ì†¡
        active_users = await self._get_active_users(share_id)
        await self._send_to_connection(connection, WSMessage(
            type=WSMessageType.CONNECT,
            share_id=share_id,
            data={"active_users": active_users},
            timestamp=datetime.utcnow()
        ))

    async def disconnect(self, user_id: str):
        if user_id not in self.user_sessions:
            return

        session = self.user_sessions[user_id]
        share_id = session.share_id

        # ì—°ê²° í•´ì œ
        if share_id in self.connections:
            self.connections[share_id].discard(session.connection)
            if not self.connections[share_id]:
                del self.connections[share_id]

        del self.user_sessions[user_id]

        # ì ‘ì† í•´ì œ ì•Œë¦¼
        await self._broadcast_to_share(share_id, WSMessage(
            type=WSMessageType.USER_LEAVE,
            share_id=share_id,
            user_id=user_id,
            data={},
            timestamp=datetime.utcnow()
        ))

    async def handle_message(self, user_id: str, message: WSMessage):
        if user_id not in self.user_sessions:
            return

        session = self.user_sessions[user_id]

        # ê¶Œí•œ ì²´í¬
        if not await self._check_message_permission(session, message):
            await self._send_error(session.connection, "Permission denied")
            return

        # ë©”ì‹œì§€ íƒ€ì…ë³„ ì²˜ë¦¬
        if message.type == WSMessageType.COURSE_UPDATE:
            await self._handle_course_edit(session, message)
        elif message.type == WSMessageType.COMMENT_ADD:
            await self._handle_comment_add(session, message)
        elif message.type == WSMessageType.COMMENT_REACTION:
            await self._handle_comment_reaction(session, message)
        elif message.type == WSMessageType.HEARTBEAT:
            await self._handle_heartbeat(session)

    async def _handle_course_edit(self, session: UserSession, message: WSMessage):
        if not session.permissions.can_edit:
            await self._send_error(session.connection, "Edit permission required")
            return

        try:
            # í¸ì§‘ ë‚´ìš© ê²€ì¦
            edit_data = CourseEditMessage.parse_obj(message.data)

            # ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸
            await self._apply_course_edit(session.share_id, edit_data, session.user_id)

            # í¸ì§‘ íˆìŠ¤í† ë¦¬ ê¸°ë¡
            await self._record_edit_history(session.share_id, session.user_id, edit_data)

            # ë‹¤ë¥¸ ì‚¬ìš©ìë“¤ì—ê²Œ ë¸Œë¡œë“œìºìŠ¤íŠ¸
            await self._broadcast_to_share(
                session.share_id,
                message,
                exclude_user=session.user_id
            )

        except Exception as e:
            logger.error(f"Course edit failed: {e}")
            await self._send_error(session.connection, "Edit operation failed")

    async def _broadcast_to_share(self, share_id: str, message: WSMessage, exclude_user: str = None):
        if share_id not in self.connections:
            return

        connections = self.connections[share_id].copy()

        for connection in connections:
            if exclude_user and connection.user_id == exclude_user:
                continue

            try:
                await self._send_to_connection(connection, message)
            except ConnectionClosed:
                # ì—°ê²°ì´ ëŠì–´ì§„ ê²½ìš° ì •ë¦¬
                self.connections[share_id].discard(connection)
                if connection.user_id in self.user_sessions:
                    del self.user_sessions[connection.user_id]
```

### 4-2. ì¶©ëŒ í•´ê²° ì‹œìŠ¤í…œ
```python
class ConflictResolver:
    def __init__(self):
        self.operation_transforms = {
            EditOperation.ADD_PLACE: self._transform_add_place,
            EditOperation.REMOVE_PLACE: self._transform_remove_place,
            EditOperation.REORDER_PLACES: self._transform_reorder_places,
            EditOperation.UPDATE_PLACE: self._transform_update_place,
        }

    async def resolve_concurrent_edits(
        self,
        share_id: str,
        pending_operations: List[EditOperationWithContext]
    ) -> List[EditOperationWithContext]:
        """ë™ì‹œ í¸ì§‘ ì¶©ëŒ í•´ê²°"""

        if len(pending_operations) <= 1:
            return pending_operations

        # íƒ€ì„ìŠ¤íƒ¬í”„ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_operations = sorted(pending_operations, key=lambda op: op.timestamp)

        resolved_operations = []

        for i, current_op in enumerate(sorted_operations):
            # ì´ì „ ì—°ì‚°ë“¤ê³¼ì˜ ì¶©ëŒ í•´ê²°
            for j in range(i):
                previous_op = sorted_operations[j]
                current_op = await self._apply_operational_transform(
                    current_op, previous_op
                )

            resolved_operations.append(current_op)

        return resolved_operations

    async def _apply_operational_transform(
        self,
        current_op: EditOperationWithContext,
        previous_op: EditOperationWithContext
    ) -> EditOperationWithContext:
        """Operational Transform ì ìš©"""

        transform_func = self.operation_transforms.get(current_op.operation.operation)
        if not transform_func:
            return current_op

        return await transform_func(current_op, previous_op)

    async def _transform_add_place(
        self,
        current_op: EditOperationWithContext,
        previous_op: EditOperationWithContext
    ) -> EditOperationWithContext:
        """ì¥ì†Œ ì¶”ê°€ ì—°ì‚°ì˜ ë³€í™˜"""

        if previous_op.operation.operation == EditOperation.ADD_PLACE:
            # ë‘ ì‚¬ìš©ìê°€ ë™ì‹œì— ì¥ì†Œë¥¼ ì¶”ê°€í•˜ëŠ” ê²½ìš°
            if current_op.operation.position >= previous_op.operation.position:
                # ì´ì „ ì¶”ê°€ë¡œ ì¸í•œ ìœ„ì¹˜ ì¡°ì •
                current_op.operation.position += 1

        elif previous_op.operation.operation == EditOperation.REMOVE_PLACE:
            # ì´ì „ì— ì¥ì†Œê°€ ì œê±°ëœ ê²½ìš°
            if current_op.operation.position > previous_op.operation.position:
                current_op.operation.position -= 1

        return current_op

    async def _transform_remove_place(
        self,
        current_op: EditOperationWithContext,
        previous_op: EditOperationWithContext
    ) -> EditOperationWithContext:
        """ì¥ì†Œ ì œê±° ì—°ì‚°ì˜ ë³€í™˜"""

        if previous_op.operation.operation == EditOperation.REMOVE_PLACE:
            if current_op.operation.place_id == previous_op.operation.place_id:
                # ë™ì¼í•œ ì¥ì†Œë¥¼ ì œê±°í•˜ë ¤ëŠ” ê²½ìš° - ë¬´íš¨í™”
                current_op.is_valid = False
            elif current_op.operation.position > previous_op.operation.position:
                # ì´ì „ ì œê±°ë¡œ ì¸í•œ ìœ„ì¹˜ ì¡°ì •
                current_op.operation.position -= 1

        elif previous_op.operation.operation == EditOperation.ADD_PLACE:
            if current_op.operation.position >= previous_op.operation.position:
                current_op.operation.position += 1

        return current_op

    async def _transform_reorder_places(
        self,
        current_op: EditOperationWithContext,
        previous_op: EditOperationWithContext
    ) -> EditOperationWithContext:
        """ì¥ì†Œ ìˆœì„œ ë³€ê²½ ì—°ì‚°ì˜ ë³€í™˜"""

        if previous_op.operation.operation in [EditOperation.ADD_PLACE, EditOperation.REMOVE_PLACE]:
            # ì¥ì†Œ ì¶”ê°€/ì œê±°ê°€ ìˆì—ˆë˜ ê²½ìš° ìˆœì„œ ì¬ê³„ì‚° í•„ìš”
            await self._recalculate_reorder_positions(current_op, previous_op)

        return current_op
```

---

## 5. ê¶Œí•œ ê´€ë¦¬ ì‹œìŠ¤í…œ

### 5-1. RBAC êµ¬í˜„
```python
class PermissionManager:
    def __init__(self):
        self.redis_client = Redis.from_url(settings.REDIS_URL)
        self.db = get_database()

    async def create_share_permissions(
        self,
        share_id: str,
        owner_id: str,
        permission_level: PermissionLevel
    ) -> SharePermissions:
        """ê³µìœ  ê¶Œí•œ ì„¤ì • ìƒì„±"""

        permissions = SharePermissions(
            share_id=share_id,
            owner_id=owner_id,
            default_permission=permission_level,
            user_permissions={},
            created_at=datetime.utcnow()
        )

        await self._save_permissions(permissions)
        return permissions

    async def check_user_permission(
        self,
        share_id: str,
        user_id: Optional[str],
        required_action: PermissionAction
    ) -> bool:
        """ì‚¬ìš©ì ê¶Œí•œ í™•ì¸"""

        # ìºì‹œì—ì„œ ê¶Œí•œ ì •ë³´ ì¡°íšŒ
        cache_key = f"permission:{share_id}:{user_id or 'anonymous'}"
        cached_permission = await self.redis_client.get(cache_key)

        if cached_permission:
            user_permission = UserPermission.parse_raw(cached_permission)
        else:
            user_permission = await self._calculate_user_permission(share_id, user_id)
            await self.redis_client.setex(
                cache_key,
                3600,  # 1ì‹œê°„ ìºì‹œ
                user_permission.json()
            )

        return self._has_permission(user_permission, required_action)

    async def _calculate_user_permission(
        self,
        share_id: str,
        user_id: Optional[str]
    ) -> UserPermission:
        """ì‚¬ìš©ì ê¶Œí•œ ê³„ì‚°"""

        share_info = await self.db.fetch_row(
            "SELECT * FROM shares WHERE share_id = $1",
            share_id
        )
        if not share_info:
            raise ShareNotFoundError(f"Share {share_id} not found")

        # ë§Œë£Œ í™•ì¸
        if share_info.get("expires_at") and share_info["expires_at"] < datetime.utcnow():
            raise ShareExpiredError(f"Share {share_id} has expired")

        # ì†Œìœ ì í™•ì¸
        if user_id and user_id == share_info["created_by"]:
            return UserPermission(
                level=PermissionLevel.EDIT,
                can_view=True,
                can_comment=True,
                can_edit=True,
                can_share=True,
                can_delete=True
            )

        # ê°œë³„ ì‚¬ìš©ì ê¶Œí•œ í™•ì¸
        if user_id and user_id in share_info.get("user_permissions", {}):
            user_level = share_info["user_permissions"][user_id]
        else:
            user_level = share_info.get("default_permission", PermissionLevel.VIEW_ONLY)

        return self._create_permission_from_level(user_level)

    def _create_permission_from_level(self, level: PermissionLevel) -> UserPermission:
        """ê¶Œí•œ ë ˆë²¨ì— ë”°ë¥¸ UserPermission ê°ì²´ ìƒì„±"""

        base_permissions = {
            "level": level,
            "can_view": True,
            "can_comment": False,
            "can_edit": False,
            "can_share": False,
            "can_delete": False
        }

        if level == PermissionLevel.COMMENT:
            base_permissions.update({
                "can_comment": True
            })
        elif level == PermissionLevel.EDIT:
            base_permissions.update({
                "can_comment": True,
                "can_edit": True,
                "can_share": True
            })

        return UserPermission(**base_permissions)

    def _has_permission(self, user_permission: UserPermission, action: PermissionAction) -> bool:
        """íŠ¹ì • ì•¡ì…˜ì— ëŒ€í•œ ê¶Œí•œ í™•ì¸"""

        permission_mapping = {
            PermissionAction.VIEW: user_permission.can_view,
            PermissionAction.COMMENT: user_permission.can_comment,
            PermissionAction.EDIT: user_permission.can_edit,
            PermissionAction.SHARE: user_permission.can_share,
            PermissionAction.DELETE: user_permission.can_delete,
        }

        return permission_mapping.get(action, False)

class PermissionAction(str, Enum):
    VIEW = "view"
    COMMENT = "comment"
    EDIT = "edit"
    SHARE = "share"
    DELETE = "delete"
```

---

## 6. ê³µìœ  ë§í¬ ì„œë¹„ìŠ¤

### 6-1. ë‹¨ì¶• URL ìƒì„±ê¸°
```python
class ShareLinkGenerator:
    def __init__(self):
        self.redis_client = Redis.from_url(settings.REDIS_URL)
        self.base_url = settings.BASE_SHARE_URL

    def generate_share_id(self) -> str:
        """ê³ ìœ í•œ ê³µìœ  ID ìƒì„±"""

        # 8ìë¦¬ alphanumeric ìƒì„±
        characters = string.ascii_letters + string.digits

        while True:
            share_id = ''.join(random.choices(characters, k=8))

            # ì¤‘ë³µ í™•ì¸
            if not await self._is_share_id_exists(share_id):
                return share_id

    async def create_share_link(self, request: ShareLinkCreateRequest, owner_id: str) -> ShareLinkResponse:
        """ê³µìœ  ë§í¬ ìƒì„±"""

        share_id = self.generate_share_id()

        # ê³µìœ  ì •ë³´ ì €ì¥
        share_data = {
            "share_id": share_id,
            "course_id": request.course_id,
            "created_by": owner_id,
            "permission_level": request.permission_level,
            "expires_at": request.expires_at,
            "allow_comments": request.allow_comments,
            "allow_edit": request.allow_edit,
            "password_hash": await self._hash_password(request.password) if request.password else None,
            "created_at": datetime.utcnow(),
            "access_count": 0,
            "last_accessed_at": None
        }

        await self.db.execute(
            """
            INSERT INTO shares (share_id, course_id, created_by, permission_level, expires_at,
                              allow_comments, allow_edit, password_hash, created_at, access_count)
            VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
            """,
            share_data["share_id"], share_data["course_id"], share_data["created_by"],
            share_data["permission_level"], share_data["expires_at"], share_data["allow_comments"],
            share_data["allow_edit"], share_data["password_hash"], share_data["created_at"], 0
        )

        # ìºì‹œì—ë„ ì €ì¥
        await self.redis_client.setex(
            f"share:{share_id}",
            86400,  # 24ì‹œê°„
            json.dumps(share_data, default=str)
        )

        # QR ì½”ë“œ ìƒì„±
        qr_code_url = await self._generate_qr_code(share_id)

        return ShareLinkResponse(
            share_id=share_id,
            share_url=f"{self.base_url}/share/{share_id}",
            qr_code_url=qr_code_url,
            permission_level=request.permission_level,
            expires_at=request.expires_at,
            created_at=share_data["created_at"]
        )

    async def get_share_info(self, share_id: str) -> Optional[Dict[str, Any]]:
        """ê³µìœ  ì •ë³´ ì¡°íšŒ"""

        # ìºì‹œì—ì„œ ë¨¼ì € ì¡°íšŒ
        cached = await self.redis_client.get(f"share:{share_id}")
        if cached:
            return json.loads(cached)

        # DBì—ì„œ ì¡°íšŒ
        share_info = await self.db.fetch_row(
            "SELECT * FROM shares WHERE share_id = $1",
            share_id
        )
        if share_info:
            # ìºì‹œì— ì €ì¥
            await self.redis_client.setex(
                f"share:{share_id}",
                86400,
                json.dumps(share_info, default=str)
            )

        return share_info

    async def increment_access_count(self, share_id: str):
        """ì ‘ê·¼ íšŸìˆ˜ ì¦ê°€"""

        current_time = datetime.utcnow()

        # DB ì—…ë°ì´íŠ¸
        await self.db.execute(
            """
            UPDATE shares
            SET access_count = access_count + 1, last_accessed_at = $1
            WHERE share_id = $2
            """,
            current_time, share_id
        )

        # ìºì‹œ ë¬´íš¨í™”
        await self.redis_client.delete(f"share:{share_id}")

    async def _generate_qr_code(self, share_id: str) -> str:
        """QR ì½”ë“œ ìƒì„±"""

        share_url = f"{self.base_url}/share/{share_id}"

        qr = qrcode.QRCode(
            version=1,
            error_correction=qrcode.constants.ERROR_CORRECT_L,
            box_size=10,
            border=4,
        )
        qr.add_data(share_url)
        qr.make(fit=True)

        # QR ì½”ë“œ ì´ë¯¸ì§€ ìƒì„±
        img = qr.make_image(fill_color="black", back_color="white")

        # S3ì— ì—…ë¡œë“œ
        img_buffer = BytesIO()
        img.save(img_buffer, format='PNG')
        img_buffer.seek(0)

        qr_code_key = f"qr_codes/{share_id}.png"
        await self._upload_to_s3(qr_code_key, img_buffer.getvalue(), "image/png")

        return f"{settings.CDN_BASE_URL}/{qr_code_key}"
```

### 6-2. ë§í¬ ë©”íƒ€ë°ì´í„° ìƒì„±
```python
class ShareMetadataGenerator:
    def __init__(self):
        self.template_engine = Jinja2Templates(directory="templates")

    async def generate_og_metadata(self, share_id: str) -> Dict[str, str]:
        """Open Graph ë©”íƒ€ë°ì´í„° ìƒì„±"""

        share_info = await self._get_share_info(share_id)
        if not share_info:
            raise ShareNotFoundError(f"Share {share_id} not found")

        course_info = await self._get_course_info(share_info["course_id"])
        thumbnail_url = await self._generate_course_thumbnail(course_info)

        metadata = {
            "og:title": f"{course_info['name']} - ë°ì´íŠ¸ ì½”ìŠ¤",
            "og:description": self._generate_course_description(course_info),
            "og:image": thumbnail_url,
            "og:url": f"{settings.BASE_SHARE_URL}/share/{share_id}",
            "og:type": "article",
            "og:site_name": "Hotly",

            # Twitter Card
            "twitter:card": "summary_large_image",
            "twitter:title": f"{course_info['name']} - ë°ì´íŠ¸ ì½”ìŠ¤",
            "twitter:description": self._generate_course_description(course_info),
            "twitter:image": thumbnail_url,

            # ì¶”ê°€ ë©”íƒ€ë°ì´í„°
            "description": self._generate_course_description(course_info),
            "keywords": "ë°ì´íŠ¸ì½”ìŠ¤,ë°ì´íŠ¸,ì—°ì¸,ì»¤í”Œ,ì¶”ì²œ"
        }

        return metadata

    async def _generate_course_thumbnail(self, course_info: Dict[str, Any]) -> str:
        """ì½”ìŠ¤ ì¸ë„¤ì¼ ì´ë¯¸ì§€ ìƒì„±"""

        # ìº”ë²„ìŠ¤ ìƒì„±
        img_width, img_height = 1200, 630  # OG ì´ë¯¸ì§€ í‘œì¤€ í¬ê¸°
        img = Image.new('RGB', (img_width, img_height), color='white')
        draw = ImageDraw.Draw(img)

        # í°íŠ¸ ë¡œë”©
        title_font = ImageFont.truetype("fonts/NotoSansKR-Bold.ttf", 48)
        desc_font = ImageFont.truetype("fonts/NotoSansKR-Regular.ttf", 24)

        # ì œëª© ê·¸ë¦¬ê¸°
        title_text = course_info['name'][:20]  # 20ì ì œí•œ
        title_bbox = draw.textbbox((0, 0), title_text, font=title_font)
        title_x = (img_width - (title_bbox[2] - title_bbox[0])) // 2
        draw.text((title_x, 150), title_text, font=title_font, fill='black')

        # ì¥ì†Œ ê°œìˆ˜ ê·¸ë¦¬ê¸°
        place_count = len(course_info.get('places', []))
        desc_text = f"{place_count}ê°œ ì¥ì†Œ â€¢ {course_info.get('total_duration', 0)}ë¶„"
        desc_bbox = draw.textbbox((0, 0), desc_text, font=desc_font)
        desc_x = (img_width - (desc_bbox[2] - desc_bbox[0])) // 2
        draw.text((desc_x, 220), desc_text, font=desc_font, fill='gray')

        # ì¥ì†Œ ì•„ì´ì½˜ë“¤ ê·¸ë¦¬ê¸°
        if place_count > 0:
            self._draw_place_icons(draw, course_info['places'][:5], img_width)

        # ë¸Œëœë“œ ë¡œê³  ì¶”ê°€
        logo_text = "Hotly"
        logo_font = ImageFont.truetype("fonts/NotoSansKR-Bold.ttf", 32)
        draw.text((50, img_height - 80), logo_text, font=logo_font, fill='#007AFF')

        # S3ì— ì—…ë¡œë“œ
        img_buffer = BytesIO()
        img.save(img_buffer, format='PNG', quality=95)
        img_buffer.seek(0)

        thumbnail_key = f"share_thumbnails/{course_info['id']}.png"
        await self._upload_to_s3(thumbnail_key, img_buffer.getvalue(), "image/png")

        return f"{settings.CDN_BASE_URL}/{thumbnail_key}"

    def _generate_course_description(self, course_info: Dict[str, Any]) -> str:
        """ì½”ìŠ¤ ì„¤ëª… í…ìŠ¤íŠ¸ ìƒì„±"""

        places = course_info.get('places', [])
        if not places:
            return "íŠ¹ë³„í•œ ë°ì´íŠ¸ ì½”ìŠ¤ë¥¼ ê³µìœ í•©ë‹ˆë‹¤."

        place_names = [place['name'] for place in places[:3]]
        description = " â†’ ".join(place_names)

        if len(places) > 3:
            description += f" ì™¸ {len(places) - 3}ê³³"

        return f"{description}ìœ¼ë¡œ ì´ì–´ì§€ëŠ” ë°ì´íŠ¸ ì½”ìŠ¤ì…ë‹ˆë‹¤."
```

---

## 7. ëŒ“ê¸€ ë° ë°˜ì‘ ì‹œìŠ¤í…œ

### 7-1. ëŒ“ê¸€ ê´€ë¦¬
```python
class CommentManager:
    def __init__(self):
        self.db = get_database()
        self.spam_filter = SpamFilter()
        self.websocket_manager = WebSocketManager()

    async def add_comment(
        self,
        request: CommentCreateRequest,
        user_id: str
    ) -> CommentResponse:
        """ëŒ“ê¸€ ì¶”ê°€"""

        # ìŠ¤íŒ¸ í•„í„°ë§
        if await self.spam_filter.is_spam(request.content, user_id):
            raise SpamDetectedError("Comment detected as spam")

        # ëŒ“ê¸€ ìƒì„±
        comment_id = str(ObjectId())
        comment_data = {
            "_id": ObjectId(comment_id),
            "share_id": request.share_id,
            "place_id": request.place_id,
            "content": request.content,
            "author_id": user_id,
            "parent_id": request.parent_id,
            "reactions": {},
            "created_at": datetime.utcnow(),
            "updated_at": None,
            "is_deleted": False
        }

        await self.db.execute(
            """
            INSERT INTO comments (id, share_id, place_id, content, author_id, parent_id,
                                reactions, created_at, is_deleted)
            VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
            """,
            comment_id, comment_data["share_id"], comment_data["place_id"],
            comment_data["content"], comment_data["author_id"], comment_data["parent_id"],
            json.dumps(comment_data["reactions"]), comment_data["created_at"], False
        )

        # ì‘ì„±ì ì •ë³´ ì¡°íšŒ
        author_info = await self._get_user_info(user_id)

        # ì‘ë‹µ ìƒì„±
        comment_response = CommentResponse(
            id=comment_id,
            content=request.content,
            author=author_info,
            place_id=request.place_id,
            parent_id=request.parent_id,
            replies_count=0,
            reactions={},
            created_at=comment_data["created_at"]
        )

        # ì‹¤ì‹œê°„ ë¸Œë¡œë“œìºìŠ¤íŠ¸
        await self.websocket_manager.broadcast_to_share(
            request.share_id,
            WSMessage(
                type=WSMessageType.COMMENT_ADD,
                share_id=request.share_id,
                user_id=user_id,
                data=comment_response.dict(),
                timestamp=datetime.utcnow()
            )
        )

        # ì•Œë¦¼ ë°œì†¡
        await self._send_comment_notification(request.share_id, comment_response)

        return comment_response

    async def add_reaction(
        self,
        request: CommentReactionRequest,
        user_id: str
    ) -> Dict[str, int]:
        """ëŒ“ê¸€ì— ë°˜ì‘ ì¶”ê°€/ì œê±°"""

        comment = await self.db.comments.find_one({"_id": ObjectId(request.comment_id)})
        if not comment:
            raise CommentNotFoundError(f"Comment {request.comment_id} not found")

        reactions = comment.get("reactions", {})
        user_reactions = reactions.get(user_id, [])

        if request.action == ReactionAction.ADD:
            if request.reaction not in user_reactions:
                user_reactions.append(request.reaction)
        else:  # REMOVE
            if request.reaction in user_reactions:
                user_reactions.remove(request.reaction)

        # ë¹ˆ ë¦¬ìŠ¤íŠ¸ë©´ ì‚¬ìš©ì ì œê±°
        if user_reactions:
            reactions[user_id] = user_reactions
        else:
            reactions.pop(user_id, None)

        # ì—…ë°ì´íŠ¸
        await self.db.comments.update_one(
            {"_id": ObjectId(request.comment_id)},
            {"$set": {"reactions": reactions}}
        )

        # ë°˜ì‘ ì§‘ê³„
        reaction_counts = self._aggregate_reactions(reactions)

        # ì‹¤ì‹œê°„ ë¸Œë¡œë“œìºìŠ¤íŠ¸
        await self.websocket_manager.broadcast_to_share(
            comment["share_id"],
            WSMessage(
                type=WSMessageType.COMMENT_REACTION,
                share_id=comment["share_id"],
                user_id=user_id,
                data={
                    "comment_id": request.comment_id,
                    "reaction": request.reaction,
                    "action": request.action,
                    "reaction_counts": reaction_counts
                },
                timestamp=datetime.utcnow()
            )
        )

        return reaction_counts

    def _aggregate_reactions(self, reactions: Dict[str, List[str]]) -> Dict[str, int]:
        """ë°˜ì‘ ì§‘ê³„"""

        counts = {}
        for user_reactions in reactions.values():
            for reaction in user_reactions:
                counts[reaction] = counts.get(reaction, 0) + 1

        return counts

    async def get_comments_for_share(
        self,
        share_id: str,
        place_id: Optional[str] = None,
        limit: int = 50,
        offset: int = 0
    ) -> List[CommentResponse]:
        """ê³µìœ  ì½”ìŠ¤ì˜ ëŒ“ê¸€ ëª©ë¡ ì¡°íšŒ"""

        query = {
            "share_id": share_id,
            "is_deleted": False
        }

        if place_id:
            query["place_id"] = place_id
        else:
            query["place_id"] = None  # ì „ì²´ ì½”ìŠ¤ ëŒ“ê¸€

        comments = await self.db.comments.find(query)\
            .sort("created_at", -1)\
            .skip(offset)\
            .limit(limit)\
            .to_list(length=None)

        # ëŒ“ê¸€ ì‘ë‹µ ë³€í™˜
        comment_responses = []
        for comment in comments:
            author_info = await self._get_user_info(comment["author_id"])
            replies_count = await self._get_replies_count(str(comment["_id"]))
            reaction_counts = self._aggregate_reactions(comment.get("reactions", {}))

            comment_responses.append(CommentResponse(
                id=str(comment["_id"]),
                content=comment["content"],
                author=author_info,
                place_id=comment.get("place_id"),
                parent_id=comment.get("parent_id"),
                replies_count=replies_count,
                reactions=reaction_counts,
                created_at=comment["created_at"],
                updated_at=comment.get("updated_at")
            ))

        return comment_responses
```

### 7-2. ìŠ¤íŒ¸ í•„í„°ë§
```python
class SpamFilter:
    def __init__(self):
        self.redis_client = Redis.from_url(settings.REDIS_URL)
        self.banned_keywords = self._load_banned_keywords()
        self.rate_limits = {
            "comments_per_minute": 10,
            "comments_per_hour": 100
        }

    async def is_spam(self, content: str, user_id: str) -> bool:
        """ìŠ¤íŒ¸ ì—¬ë¶€ íŒë‹¨"""

        # í‚¤ì›Œë“œ í•„í„°ë§
        if self._contains_banned_keywords(content):
            await self._record_spam_attempt(user_id, "banned_keywords")
            return True

        # ê¸¸ì´ ì²´í¬
        if len(content) < 2 or len(content) > 500:
            return True

        # ë°˜ë³µ ì²´í¬
        if self._is_repetitive_content(content):
            await self._record_spam_attempt(user_id, "repetitive")
            return True

        # ì†ë„ ì œí•œ ì²´í¬
        if await self._check_rate_limit(user_id):
            await self._record_spam_attempt(user_id, "rate_limit")
            return True

        # URL ìŠ¤íŒ¸ ì²´í¬
        if self._contains_suspicious_urls(content):
            await self._record_spam_attempt(user_id, "suspicious_url")
            return True

        return False

    def _contains_banned_keywords(self, content: str) -> bool:
        """ê¸ˆì§€ í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€"""

        content_lower = content.lower()
        return any(keyword in content_lower for keyword in self.banned_keywords)

    def _is_repetitive_content(self, content: str) -> bool:
        """ë°˜ë³µì ì¸ ë‚´ìš© ì—¬ë¶€"""

        # ë™ì¼ ë¬¸ìê°€ 5ë²ˆ ì´ìƒ ë°˜ë³µ
        if re.search(r'(.)\1{4,}', content):
            return True

        # ë™ì¼ ë‹¨ì–´ê°€ 3ë²ˆ ì´ìƒ ë°˜ë³µ
        words = content.split()
        word_counts = {}
        for word in words:
            word_counts[word] = word_counts.get(word, 0) + 1
            if word_counts[word] >= 3:
                return True

        return False

    async def _check_rate_limit(self, user_id: str) -> bool:
        """ì†ë„ ì œí•œ í™•ì¸"""

        # ë¶„ë‹¹ ì œí•œ í™•ì¸
        minute_key = f"comment_rate:{user_id}:{datetime.utcnow().strftime('%Y%m%d%H%M')}"
        minute_count = await self.redis_client.get(minute_key)

        if minute_count and int(minute_count) >= self.rate_limits["comments_per_minute"]:
            return True

        # ì‹œê°„ë‹¹ ì œí•œ í™•ì¸
        hour_key = f"comment_rate:{user_id}:{datetime.utcnow().strftime('%Y%m%d%H')}"
        hour_count = await self.redis_client.get(hour_key)

        if hour_count and int(hour_count) >= self.rate_limits["comments_per_hour"]:
            return True

        # ì¹´ìš´íŠ¸ ì¦ê°€
        await self.redis_client.incr(minute_key)
        await self.redis_client.expire(minute_key, 60)
        await self.redis_client.incr(hour_key)
        await self.redis_client.expire(hour_key, 3600)

        return False

    def _contains_suspicious_urls(self, content: str) -> bool:
        """ì˜ì‹¬ìŠ¤ëŸ¬ìš´ URL í¬í•¨ ì—¬ë¶€"""

        url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'
        urls = re.findall(url_pattern, content)

        if len(urls) > 2:  # URLì´ 2ê°œ ì´ˆê³¼
            return True

        # ì•Œë ¤ì§„ ìŠ¤íŒ¸ ë„ë©”ì¸ ì²´í¬
        spam_domains = ['bit.ly', 'tinyurl.com', 'short.link']  # ì˜ˆì‹œ
        for url in urls:
            domain = urlparse(url).netloc
            if any(spam_domain in domain for spam_domain in spam_domains):
                return True

        return False
```

---

## 8. ì„±ëŠ¥ ìµœì í™”

### 8-1. WebSocket ì—°ê²° ìµœì í™”
```python
class WebSocketOptimizer:
    def __init__(self):
        self.connection_pool = ConnectionPool()
        self.message_queue = MessageQueue()
        self.heartbeat_manager = HeartbeatManager()

    async def optimize_connection(self, connection: WebSocketConnection):
        """WebSocket ì—°ê²° ìµœì í™”"""

        # ì••ì¶• ì„¤ì •
        await self._enable_compression(connection)

        # ë°°ì¹˜ ë©”ì‹œì§€ ì²˜ë¦¬
        await self._setup_message_batching(connection)

        # í•˜íŠ¸ë¹„íŠ¸ ìµœì í™”
        await self.heartbeat_manager.setup_adaptive_heartbeat(connection)

    async def _enable_compression(self, connection: WebSocketConnection):
        """ë©”ì‹œì§€ ì••ì¶• í™œì„±í™”"""

        if connection.supports_compression:
            connection.compression_enabled = True
            connection.compression_threshold = 1024  # 1KB ì´ìƒ ë©”ì‹œì§€ë§Œ ì••ì¶•

    async def _setup_message_batching(self, connection: WebSocketConnection):
        """ë©”ì‹œì§€ ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •"""

        connection.batch_buffer = []
        connection.batch_timeout = 100  # 100ms
        connection.max_batch_size = 10

        # ë°°ì¹˜ íƒ€ì´ë¨¸ ì„¤ì •
        asyncio.create_task(self._batch_message_sender(connection))

    async def _batch_message_sender(self, connection: WebSocketConnection):
        """ë°°ì¹˜ ë©”ì‹œì§€ ì „ì†¡"""

        while connection.is_active:
            await asyncio.sleep(connection.batch_timeout / 1000)

            if connection.batch_buffer:
                batched_message = {
                    "type": "batch",
                    "messages": connection.batch_buffer.copy(),
                    "timestamp": datetime.utcnow().isoformat()
                }

                await connection.send(batched_message)
                connection.batch_buffer.clear()

class HeartbeatManager:
    def __init__(self):
        self.base_interval = 30  # 30ì´ˆ ê¸°ë³¸ ê°„ê²©
        self.adaptive_intervals = {}

    async def setup_adaptive_heartbeat(self, connection: WebSocketConnection):
        """ì ì‘í˜• í•˜íŠ¸ë¹„íŠ¸ ì„¤ì •"""

        connection.heartbeat_interval = self.base_interval
        connection.missed_heartbeats = 0
        connection.last_heartbeat = datetime.utcnow()

        asyncio.create_task(self._heartbeat_loop(connection))

    async def _heartbeat_loop(self, connection: WebSocketConnection):
        """í•˜íŠ¸ë¹„íŠ¸ ë£¨í”„"""

        while connection.is_active:
            await asyncio.sleep(connection.heartbeat_interval)

            try:
                await connection.send({
                    "type": "heartbeat",
                    "timestamp": datetime.utcnow().isoformat()
                })

                # ì‘ë‹µ ëŒ€ê¸°
                response = await asyncio.wait_for(
                    connection.wait_for_pong(),
                    timeout=10.0
                )

                if response:
                    connection.missed_heartbeats = 0
                    await self._adjust_heartbeat_interval(connection)
                else:
                    await self._handle_missed_heartbeat(connection)

            except asyncio.TimeoutError:
                await self._handle_missed_heartbeat(connection)
            except Exception as e:
                logger.error(f"Heartbeat error: {e}")
                break

    async def _adjust_heartbeat_interval(self, connection: WebSocketConnection):
        """í•˜íŠ¸ë¹„íŠ¸ ê°„ê²© ì¡°ì •"""

        # ì—°ê²° í’ˆì§ˆì— ë”°ë¼ ê°„ê²© ì¡°ì •
        if connection.latency < 100:  # 100ms ë¯¸ë§Œ
            connection.heartbeat_interval = min(60, connection.heartbeat_interval + 5)
        elif connection.latency > 500:  # 500ms ì´ˆê³¼
            connection.heartbeat_interval = max(15, connection.heartbeat_interval - 5)

    async def _handle_missed_heartbeat(self, connection: WebSocketConnection):
        """í•˜íŠ¸ë¹„íŠ¸ ëˆ„ë½ ì²˜ë¦¬"""

        connection.missed_heartbeats += 1

        if connection.missed_heartbeats >= 3:
            logger.warning(f"Connection {connection.user_id} missed 3 heartbeats, closing")
            await connection.close()
        else:
            # ê°„ê²© ë‹¨ì¶•
            connection.heartbeat_interval = max(10, connection.heartbeat_interval - 5)
```

### 8-2. ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”
```python
class ShareDatabaseOptimizer:
    def __init__(self):
        self.db = get_database()
        self.query_cache = {}

    async def optimize_share_queries(self):
        """ê³µìœ  ê´€ë ¨ ì¿¼ë¦¬ ìµœì í™”"""

        # ì¸ë±ìŠ¤ ìƒì„±
        await self._create_indexes()

        # ì¿¼ë¦¬ ê³„íš ìµœì í™”
        await self._optimize_query_plans()

    async def _create_indexes(self):
        """ì¸ë±ìŠ¤ ìƒì„±"""

        # ê³µìœ  ì»¬ë ‰ì…˜ ì¸ë±ìŠ¤
        await self.db.shares.create_index([
            ("share_id", 1)
        ], unique=True)

        await self.db.shares.create_index([
            ("created_by", 1),
            ("created_at", -1)
        ])

        await self.db.shares.create_index([
            ("expires_at", 1)
        ], expireAfterSeconds=0)

        # ëŒ“ê¸€ ì»¬ë ‰ì…˜ ì¸ë±ìŠ¤
        await self.db.comments.create_index([
            ("share_id", 1),
            ("place_id", 1),
            ("created_at", -1)
        ])

        await self.db.comments.create_index([
            ("share_id", 1),
            ("parent_id", 1)
        ])

        # í¸ì§‘ íˆìŠ¤í† ë¦¬ ì¸ë±ìŠ¤
        await self.db.edit_history.create_index([
            ("share_id", 1),
            ("timestamp", -1)
        ])

    async def get_share_with_cache(self, share_id: str) -> Optional[Dict[str, Any]]:
        """ìºì‹œëœ ê³µìœ  ì •ë³´ ì¡°íšŒ"""

        # ìºì‹œ í™•ì¸
        cache_key = f"share_detail:{share_id}"
        cached = await self.redis_client.get(cache_key)

        if cached:
            return json.loads(cached)

        # ì§‘ê³„ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ëª¨ë“  ì •ë³´ í•œ ë²ˆì— ì¡°íšŒ
        pipeline = [
            {"$match": {"share_id": share_id}},
            {"$lookup": {
                "from": "courses",
                "localField": "course_id",
                "foreignField": "_id",
                "as": "course_info"
            }},
            {"$lookup": {
                "from": "comments",
                "localField": "share_id",
                "foreignField": "share_id",
                "as": "comments"
            }},
            {"$addFields": {
                "comments_count": {"$size": "$comments"},
                "recent_comments": {
                    "$slice": [
                        {"$sortArray": {
                            "input": "$comments",
                            "sortBy": {"created_at": -1}
                        }},
                        5
                    ]
                }
            }},
            {"$project": {
                "comments": 0  # ì „ì²´ ëŒ“ê¸€ ë°°ì—´ ì œì™¸
            }}
        ]

        result = await self.db.shares.aggregate(pipeline).to_list(1)

        if result:
            share_info = result[0]
            # ìºì‹œ ì €ì¥ (5ë¶„)
            await self.redis_client.setex(
                cache_key,
                300,
                json.dumps(share_info, default=str)
            )
            return share_info

        return None
```

---

## 9. ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

### 9-1. ê³µìœ  ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
```python
from prometheus_client import Counter, Histogram, Gauge

class SharingMetrics:
    def __init__(self):
        self.share_creates = Counter(
            'share_creates_total',
            'Total share link creations',
            ['permission_level']
        )

        self.share_accesses = Counter(
            'share_accesses_total',
            'Total share link accesses',
            ['share_id', 'user_type']  # owner, collaborator, anonymous
        )

        self.websocket_connections = Gauge(
            'websocket_connections_current',
            'Current WebSocket connections',
            ['share_id']
        )

        self.collaboration_events = Counter(
            'collaboration_events_total',
            'Total collaboration events',
            ['event_type', 'share_id']
        )

        self.comment_operations = Counter(
            'comment_operations_total',
            'Total comment operations',
            ['operation', 'share_id']
        )

        self.message_latency = Histogram(
            'websocket_message_latency_seconds',
            'WebSocket message processing latency',
            ['message_type']
        )

    def record_share_creation(self, permission_level: str):
        self.share_creates.labels(permission_level=permission_level).inc()

    def record_share_access(self, share_id: str, user_type: str):
        self.share_accesses.labels(share_id=share_id, user_type=user_type).inc()

    def update_websocket_connections(self, share_id: str, count: int):
        self.websocket_connections.labels(share_id=share_id).set(count)

    def record_collaboration_event(self, event_type: str, share_id: str):
        self.collaboration_events.labels(
            event_type=event_type,
            share_id=share_id
        ).inc()

class SharingAnalytics:
    def __init__(self):
        self.db = get_database()
        self.metrics = SharingMetrics()

    async def track_sharing_usage(self):
        """ê³µìœ  ì‚¬ìš©ëŸ‰ ë¶„ì„"""

        # ì¼ì¼ ê³µìœ  ìƒì„±ëŸ‰
        today = datetime.utcnow().replace(hour=0, minute=0, second=0, microsecond=0)
        daily_shares = await self.db.shares.count_documents({
            "created_at": {"$gte": today}
        })

        # í™œì„± ê³µìœ  ë§í¬ ìˆ˜
        active_shares = await self.db.shares.count_documents({
            "$or": [
                {"expires_at": None},
                {"expires_at": {"$gt": datetime.utcnow()}}
            ]
        })

        # í‰ê·  ì ‘ê·¼ íšŸìˆ˜
        avg_access = await self.db.shares.aggregate([
            {"$group": {
                "_id": None,
                "avg_access": {"$avg": "$access_count"}
            }}
        ]).to_list(1)

        analytics_data = {
            "daily_shares": daily_shares,
            "active_shares": active_shares,
            "avg_access_per_share": avg_access[0]["avg_access"] if avg_access else 0,
            "timestamp": datetime.utcnow()
        }

        # ë¶„ì„ ê²°ê³¼ ì €ì¥
        await self.db.sharing_analytics.insert_one(analytics_data)

        return analytics_data

    async def analyze_collaboration_patterns(self, share_id: str):
        """í˜‘ì—… íŒ¨í„´ ë¶„ì„"""

        # í¸ì§‘ íˆìŠ¤í† ë¦¬ ë¶„ì„
        edit_history = await self.db.edit_history.find({
            "share_id": share_id
        }).sort("timestamp", 1).to_list(None)

        # ëŒ“ê¸€ ë¶„ì„
        comments = await self.db.comments.find({
            "share_id": share_id
        }).sort("created_at", 1).to_list(None)

        # íŒ¨í„´ ë¶„ì„
        patterns = {
            "total_edits": len(edit_history),
            "total_comments": len(comments),
            "unique_editors": len(set(edit["user_id"] for edit in edit_history)),
            "unique_commenters": len(set(comment["author_id"] for comment in comments)),
            "edit_frequency": self._calculate_edit_frequency(edit_history),
            "comment_frequency": self._calculate_comment_frequency(comments),
            "peak_activity_hours": self._find_peak_activity_hours(edit_history + comments)
        }

        return patterns
```

---

## 10. í…ŒìŠ¤íŠ¸ ì „ëµ

### 10-1. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (TDD)
```python
class TestSharingSystem:
    @pytest.fixture
    async def share_service(self):
        return ShareLinkGenerator()

    @pytest.fixture
    async def websocket_manager(self):
        return WebSocketManager()

    async def test_share_link_creation(self, share_service):
        # Given
        request = ShareLinkCreateRequest(
            course_id="test_course_123",
            permission_level=PermissionLevel.COMMENT,
            allow_comments=True,
            allow_edit=False
        )
        owner_id = "user_123"

        # When
        response = await share_service.create_share_link(request, owner_id)

        # Then
        assert len(response.share_id) == 8
        assert response.share_url.endswith(f"/share/{response.share_id}")
        assert response.permission_level == PermissionLevel.COMMENT
        assert response.qr_code_url is not None
        assert response.created_at is not None

    async def test_share_access_permission_check(self, share_service):
        # Given
        share_id = "test1234"
        await self._create_test_share(share_id, PermissionLevel.VIEW_ONLY)

        # When - VIEW permission
        can_view = await share_service.check_permission(share_id, None, PermissionAction.VIEW)
        can_comment = await share_service.check_permission(share_id, None, PermissionAction.COMMENT)

        # Then
        assert can_view is True
        assert can_comment is False

    async def test_websocket_connection_and_broadcast(self, websocket_manager):
        # Given
        mock_websocket1 = MockWebSocket()
        mock_websocket2 = MockWebSocket()
        share_id = "test_share"

        # When - ë‘ ì‚¬ìš©ì ì—°ê²°
        await websocket_manager.connect(mock_websocket1, share_id, "valid_token_1")
        await websocket_manager.connect(mock_websocket2, share_id, "valid_token_2")

        # ë©”ì‹œì§€ ë¸Œë¡œë“œìºìŠ¤íŠ¸
        test_message = WSMessage(
            type=WSMessageType.COMMENT_ADD,
            share_id=share_id,
            user_id="user_1",
            data={"comment": "test comment"},
            timestamp=datetime.utcnow()
        )

        await websocket_manager.handle_message("user_1", test_message)

        # Then
        assert len(websocket_manager.connections[share_id]) == 2
        # user_2ë§Œ ë©”ì‹œì§€ë¥¼ ë°›ì•„ì•¼ í•¨ (ë°œì†¡ì ì œì™¸)
        assert mock_websocket2.received_messages[-1]["type"] == WSMessageType.COMMENT_ADD
        assert len(mock_websocket1.received_messages) == 1  # ì—°ê²° ë©”ì‹œì§€ë§Œ

    async def test_concurrent_edit_conflict_resolution(self):
        # Given
        resolver = ConflictResolver()

        # ë™ì‹œì— ê°™ì€ ìœ„ì¹˜ì— ì¥ì†Œ ì¶”ê°€í•˜ëŠ” ì‹œë‚˜ë¦¬ì˜¤
        op1 = EditOperationWithContext(
            operation=CourseEditMessage(
                operation=EditOperation.ADD_PLACE,
                position=2,
                data={"place_id": "place_1"}
            ),
            user_id="user_1",
            timestamp=datetime.utcnow()
        )

        op2 = EditOperationWithContext(
            operation=CourseEditMessage(
                operation=EditOperation.ADD_PLACE,
                position=2,
                data={"place_id": "place_2"}
            ),
            user_id="user_2",
            timestamp=datetime.utcnow() + timedelta(milliseconds=100)
        )

        # When
        resolved = await resolver.resolve_concurrent_edits("test_share", [op1, op2])

        # Then
        assert len(resolved) == 2
        assert resolved[0].operation.position == 2  # ì²« ë²ˆì§¸ëŠ” ê·¸ëŒ€ë¡œ
        assert resolved[1].operation.position == 3  # ë‘ ë²ˆì§¸ëŠ” í•œ ì¹¸ ë°€ë¦¼

    async def test_comment_spam_filtering(self):
        # Given
        spam_filter = SpamFilter()
        user_id = "test_user"

        # When & Then - ë‹¤ì–‘í•œ ìŠ¤íŒ¸ ì‹œë‚˜ë¦¬ì˜¤

        # ê¸ˆì§€ í‚¤ì›Œë“œ
        assert await spam_filter.is_spam("ì´ê²ƒì€ ê´‘ê³ ì…ë‹ˆë‹¤", user_id) is True

        # ë°˜ë³µ ë¬¸ì
        assert await spam_filter.is_spam("ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹", user_id) is True

        # ì •ìƒ ëŒ“ê¸€
        assert await spam_filter.is_spam("ì¢‹ì€ ì½”ìŠ¤ë„¤ìš”!", user_id) is False

        # ë„ˆë¬´ ì§§ì€ ëŒ“ê¸€
        assert await spam_filter.is_spam("ã…‹", user_id) is True

        # URL ìŠ¤íŒ¸
        assert await spam_filter.is_spam("ì—¬ê¸° ë³´ì„¸ìš” http://spam.com http://bad.com http://evil.com", user_id) is True
```

### 10-2. í†µí•© í…ŒìŠ¤íŠ¸
```python
class TestSharingIntegration:
    @pytest.mark.integration
    async def test_full_sharing_workflow(self, test_client, postgresql, redis_client):
        # Given
        user1_token = await create_test_user_token("user1")
        user2_token = await create_test_user_token("user2")
        course_id = await create_test_course("user1")

        # 1. ê³µìœ  ë§í¬ ìƒì„±
        share_response = await test_client.post(
            "/api/v1/shares",
            json={
                "course_id": course_id,
                "permission_level": "comment",
                "allow_comments": True
            },
            headers={"Authorization": f"Bearer {user1_token}"}
        )

        assert share_response.status_code == 201
        share_data = share_response.json()
        share_id = share_data["share_id"]

        # 2. ë‹¤ë¥¸ ì‚¬ìš©ìê°€ ê³µìœ  ë§í¬ ì ‘ê·¼
        access_response = await test_client.get(
            f"/api/v1/shares/{share_id}",
            headers={"Authorization": f"Bearer {user2_token}"}
        )

        assert access_response.status_code == 200
        access_data = access_response.json()
        assert access_data["can_comment"] is True
        assert access_data["can_edit"] is False

        # 3. ëŒ“ê¸€ ì‘ì„±
        comment_response = await test_client.post(
            f"/api/v1/shares/{share_id}/comments",
            json={
                "content": "ë©‹ì§„ ì½”ìŠ¤ë„¤ìš”!",
                "place_id": None
            },
            headers={"Authorization": f"Bearer {user2_token}"}
        )

        assert comment_response.status_code == 201

        # 4. ëŒ“ê¸€ ëª©ë¡ ì¡°íšŒ
        comments_response = await test_client.get(
            f"/api/v1/shares/{share_id}/comments"
        )

        assert comments_response.status_code == 200
        comments = comments_response.json()
        assert len(comments) == 1
        assert comments[0]["content"] == "ë©‹ì§„ ì½”ìŠ¤ë„¤ìš”!"

    @pytest.mark.integration
    async def test_real_time_collaboration(self, test_client):
        # Given
        share_id = await create_test_share_with_edit_permission()

        # WebSocket ì—°ê²° ì‹œë®¬ë ˆì´ì…˜
        websocket1 = TestWebSocketClient()
        websocket2 = TestWebSocketClient()

        await websocket1.connect(f"/ws/shares/{share_id}")
        await websocket2.connect(f"/ws/shares/{share_id}")

        # When - user1ì´ ì¥ì†Œ ì¶”ê°€
        edit_message = {
            "type": "course_update",
            "data": {
                "operation": "add_place",
                "position": 1,
                "data": {"place_id": "new_place_123"}
            }
        }

        await websocket1.send_json(edit_message)

        # Then - user2ê°€ ì‹¤ì‹œê°„ìœ¼ë¡œ ë°›ì•„ì•¼ í•¨
        received = await websocket2.receive_json(timeout=5)
        assert received["type"] == "course_update"
        assert received["data"]["operation"] == "add_place"
```

### 10-3. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
```python
class TestSharingPerformance:
    @pytest.mark.performance
    async def test_concurrent_websocket_connections(self):
        """ë™ì‹œ WebSocket ì—°ê²° ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""

        share_id = "perf_test_share"
        connection_count = 100

        # Given
        websockets = []
        for i in range(connection_count):
            ws = TestWebSocketClient()
            websockets.append(ws)

        # When - ë™ì‹œ ì—°ê²°
        start_time = time.time()

        connect_tasks = [
            ws.connect(f"/ws/shares/{share_id}")
            for ws in websockets
        ]

        await asyncio.gather(*connect_tasks)

        connection_time = time.time() - start_time

        # Then
        assert connection_time < 5.0  # 5ì´ˆ ì´ë‚´ ì—°ê²°
        assert all(ws.is_connected for ws in websockets)

        # ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        broadcast_start = time.time()

        test_message = {
            "type": "comment_add",
            "data": {"comment": "performance test"}
        }

        await websockets[0].send_json(test_message)

        # ëª¨ë“  ì—°ê²°ì´ ë©”ì‹œì§€ë¥¼ ë°›ì„ ë•Œê¹Œì§€ ëŒ€ê¸°
        for ws in websockets[1:]:
            await ws.receive_json(timeout=2)

        broadcast_time = time.time() - broadcast_start

        assert broadcast_time < 2.0  # 2ì´ˆ ì´ë‚´ ë¸Œë¡œë“œìºìŠ¤íŠ¸

    @pytest.mark.performance
    async def test_share_link_generation_performance(self):
        """ê³µìœ  ë§í¬ ìƒì„± ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""

        share_service = ShareLinkGenerator()
        generation_count = 1000

        # When
        start_time = time.time()

        generation_tasks = [
            share_service.create_share_link(
                ShareLinkCreateRequest(
                    course_id=f"course_{i}",
                    permission_level=PermissionLevel.VIEW_ONLY
                ),
                owner_id=f"user_{i}"
            )
            for i in range(generation_count)
        ]

        results = await asyncio.gather(*generation_tasks)

        total_time = time.time() - start_time

        # Then
        assert total_time < 30.0  # 30ì´ˆ ì´ë‚´ì— 1000ê°œ ìƒì„±
        assert len(results) == generation_count
        assert all(len(r.share_id) == 8 for r in results)

        # ì¤‘ë³µ ID ê²€ì‚¬
        share_ids = [r.share_id for r in results]
        assert len(set(share_ids)) == generation_count  # ëª¨ë‘ unique
```

---

## 11. ë°°í¬ ë° ìš´ì˜

### 11-1. Docker êµ¬ì„±
```dockerfile
# Dockerfile
FROM python:3.11-slim

WORKDIR /app

# ì‹œìŠ¤í…œ ì˜ì¡´ì„±
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    libffi-dev \
    && rm -rf /var/lib/apt/lists/*

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

# WebSocket í¬íŠ¸ ë…¸ì¶œ
EXPOSE 8000 8001

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=30s --retries=3 \
    CMD python healthcheck.py

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000", "--ws-ping-interval", "20", "--ws-ping-timeout", "10"]
```

### 11-2. Kubernetes ë°°í¬
```yaml
# sharing-service-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sharing-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: sharing-service
  template:
    metadata:
      labels:
        app: sharing-service
    spec:
      containers:
      - name: sharing-service
        image: hotly/sharing-service:latest
        ports:
        - containerPort: 8000
          name: http
        - containerPort: 8001
          name: websocket
        env:
        - name: REDIS_URL
          valueFrom:
            secretKeyRef:
              name: redis-secret
              key: url
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: postgresql-secret
              key: url
        - name: WEBSOCKET_MAX_CONNECTIONS
          value: "1000"
        resources:
          requests:
            memory: "512Mi"
            cpu: "300m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 10

---
apiVersion: v1
kind: Service
metadata:
  name: sharing-service
spec:
  selector:
    app: sharing-service
  ports:
  - name: http
    port: 80
    targetPort: 8000
  - name: websocket
    port: 8001
    targetPort: 8001
  type: ClusterIP

---
# WebSocketìš© ë³„ë„ ì„œë¹„ìŠ¤
apiVersion: v1
kind: Service
metadata:
  name: sharing-websocket
spec:
  selector:
    app: sharing-service
  ports:
  - port: 8001
    targetPort: 8001
  type: LoadBalancer
  sessionAffinity: ClientIP  # ì„¸ì…˜ ìœ ì§€
```

---

## 12. ìš©ì–´ ì‚¬ì „ (Technical)
- **WebSocket:** ì–‘ë°©í–¥ ì‹¤ì‹œê°„ í†µì‹ ì„ ìœ„í•œ í”„ë¡œí† ì½œ
- **Operational Transform (OT):** ë™ì‹œ í¸ì§‘ ì‹œ ì¶©ëŒì„ í•´ê²°í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜
- **RBAC (Role-Based Access Control):** ì—­í•  ê¸°ë°˜ ì ‘ê·¼ ì œì–´
- **Short URL:** ê¸´ URLì„ ì§§ê²Œ ë³€í™˜í•œ ë§í¬
- **Rate Limiting:** API í˜¸ì¶œ íšŸìˆ˜ ì œí•œ
- **Circuit Breaker:** ì¥ì•  ì „íŒŒ ë°©ì§€ë¥¼ ìœ„í•œ íŒ¨í„´
- **Message Batching:** ì—¬ëŸ¬ ë©”ì‹œì§€ë¥¼ ë¬¶ì–´ì„œ ì „ì†¡í•˜ëŠ” ìµœì í™” ê¸°ë²•

---

## Changelog
- 2025-01-XX: ì´ˆê¸° TRD ë¬¸ì„œ ì‘ì„± (ì‘ì„±ì: Claude)
- PRD 05-sharing-system ë²„ì „ê³¼ ì—°ë™
